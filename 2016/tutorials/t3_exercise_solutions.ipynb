{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: exercise\n",
    "\n",
    "(c) 2016 Justin Bois. This work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "*This tutorial exercise was generated from an Jupyter notebook.  You can download the notebook [here](t3_exercise_solutions.ipynb). Use this downloaded Jupyter notebook to fill out your responses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "When performing parameter estimation by optimization, after we find the MAP, why do we locally approximate the posterior near the MAP as Gaussian?\n",
    "\n",
    "#### Answer\n",
    "\n",
    "Any analytic peaked function can be locally approximated as Gaussian because we can expand its logarithm in a Taylor series to second order. Upon exponentiation, the result is a (possibly multivariate) Gaussian.\n",
    "\n",
    "This proves convenient because we can compute approximate error bars, assuming the posterior is Gaussian, since we know that the covariance matrix is the negative inverse of the Hessian of the log posterior evaluated at the MAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "You may have heard that curve fitting involved \"minimizing the sum of the square of the residuals.\" If indeed finding the MAP is equivalent to minimizing the sum of the square of the residuals, what underlying assumptions are there in the statistical model?\n",
    "\n",
    "#### Answer\n",
    "\n",
    "The assumption is that the data are Gaussian distributed about the prediction of the mathematical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "How would you expect each of the following to be distributed?\n",
    "\n",
    "**a)** The amount of time between repressor-operator binding events.\n",
    "\n",
    "**b)** The number of times a repressor binds its operator in a given hour.\n",
    "\n",
    "**c)** The amount of time (in total minutes of baseball played) between no-hitters in Major League Baseball.\n",
    "\n",
    "**d)** The number of no-hitters in a Major League Baseball season.\n",
    "\n",
    "To answer this question, try to match these biological stories to the stories of named distributions. For those of you not familiar with baseball, a no-hitter is a game in which a team concedes no hits to the opposing team. There have only been a few hundred no-hitters in over 200,000 MLB games.\n",
    "\n",
    "#### Answer\n",
    "\n",
    "**a)** Exponential. The waiting time between arrivals of a Poisson process are Exponentially distributed.\n",
    "\n",
    "**b)** Poisson. The number of arrivals of a Poisson process per unit time is Poisson distributed.\n",
    "\n",
    "**c)** Exponential. We are again waiting for arrivals of a Poisson process.\n",
    "\n",
    "**d)** Poisson."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
