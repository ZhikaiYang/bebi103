{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE/Bi 103, Fall 2015: Homework 6\n",
    "\n",
    "## Due 1pm, Monday, November 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This document was generated from a Jupyter notebook.  You can download the notebook [here](hw6.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.misc\n",
    "import scipy.stats as st\n",
    "import scipy.special\n",
    "\n",
    "# The MCMC Hammer\n",
    "import emcee\n",
    "\n",
    "# Numba for speed\n",
    "import numba\n",
    "\n",
    "# BE/Bi 103 utilities\n",
    "import bebi103\n",
    "\n",
    "# Import plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import corner\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables high res graphics inline (only use with static plots (non-Bokeh))\n",
    "# SVG is preferred, but there is a bug in Jupyter with vertical lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# JB's favorite Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': 'DFDFE5'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "\n",
    "# Suppress future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.1: Microtubule catastrophe, 70 pts + 15 pts extra credit\n",
    "\n",
    "In [Homework 1](hw1.html), we plotted data of microtubule catastrophe times.  In this problem, we return to the data from the [Gardner, Zanic, et al. paper](../protected/papers/gardner_2011.pdf)  We will carefully analyze the data and make some conclusions about the processes underlying microtubule catastrophe.  You can download the data set [here](../protected/data/gardner_hw6.zip).\n",
    "\n",
    "In the file `gardner_mt_catastrophe_only_tubulin.csv`, we have observed catastrophe times of microtubules with different concentrations of tubulin.  So, our data set $D$ consists of a set of measurements of the amount of time to catastrophe; $D = \\{t_i\\}$.  To model microtuble catastrophe, we will assume that a series of $m$,  processes must occur sequentially to trigger catastrophe.  This could be separate depolymerization events, binding of auxiliary proteins, etc.  We assume that each of these processes is a Poisson process, and that process $j$ occurs with rate $1/\\tau_j$.  Our goal here is to do model selection to determine the value of $m$.\n",
    "\n",
    "As we have learned, the model specifies the likelihood.  We will assume all microtubule catastrophes are independent, so the likelihood for all of our observed catastrophes \n",
    "\n",
    "\\begin{align}\n",
    "P(D\\mid \\boldsymbol{\\tau}, m, I) = \\prod_i P(t_i\\mid \\boldsymbol{\\tau}, m, I).\n",
    "\\end{align}\n",
    "\n",
    "**a)** Explain why the probability distribution for catastrophe times for a three-step process ($m=3$) is\n",
    "\n",
    "\\begin{align}\n",
    "P(t\\mid \\tau_1, \\tau_2, \\tau_3, 3, I) = \\frac{1}{\\tau_1\\tau_2\\tau_3}\\int_0^t\\mathrm{d}t_1 \\int_{t_1}^t\\mathrm{d}t_2\\, \\mathrm{e}^{-t_1/\\tau_1}\\,\\mathrm{e}^{-(t_2-t_1)/\\tau_2}\\,\\mathrm{e}^{-(t-t_2)/\\tau_3}.\n",
    "\\end{align}\n",
    "\n",
    "**b)** The above expression for general $m$ can be integrated, giving\n",
    "\n",
    "\\begin{align}\n",
    "P(t\\mid \\boldsymbol{\\tau}, m, I) = \\sum_{j=1}^m \\frac{\\tau_j^{m-2}\\,\\mathrm{e}^{-t/\\tau_j}}{\\prod_{k=1,k\\ne j}^m (\\tau_j - \\tau_k)}.\n",
    "\\end{align}\n",
    "\n",
    "For clarity, the probability distributions for the first few $m$ are\n",
    "\n",
    "\\begin{align}\n",
    "P(t\\mid \\tau_1, 1, I) &= \\frac{\\mathrm{e}^{-t/\\tau_1}}{\\tau_1},\\\\[1em]\n",
    "P(t\\mid \\tau_1, \\tau_2, 2, I) &=\n",
    "\\frac{\\mathrm{e}^{-t/\\tau_1}}{\\tau_1 - \\tau_2} + \\frac{\\mathrm{e}^{-t/\\tau_2}}{\\tau_2 - \\tau_1}\n",
    "= \\frac{\\mathrm{e}^{-t/\\tau_2} - \\mathrm{e}^{-t/\\tau_1}}{\\tau_2 - \\tau_1} \\\\[1em]\n",
    "P(t\\mid \\tau_1, \\tau_2, \\tau_3, 3, I) &=\n",
    "\\frac{\\tau_1\\,\\mathrm{e}^{-t/\\tau_1}}{(\\tau_1 - \\tau_2)(\\tau_1-\\tau_3)}\n",
    "+\\frac{\\tau_2\\,\\mathrm{e}^{-t/\\tau_2}}{(\\tau_2 - \\tau_1)(\\tau_2-\\tau_3)}\n",
    "+\\frac{\\tau_3\\,\\mathrm{e}^{-t/\\tau_3}}{(\\tau_3 - \\tau_1)(\\tau_3-\\tau_2)}\n",
    "\\end{align}\n",
    "\n",
    "Note that these probability distributions assume that no two of the $\\tau_j$'s are equal, and you should explicitly ensure this in your calculations.  If any two $\\tau_j$'s are equal, you need to take a limit, e.g.,\n",
    "\n",
    "\\begin{align}\n",
    "\\lim_{\\tau_2\\to\\tau_1} P(t\\mid \\tau_1, \\tau_2, 2, I) &= \\frac{t^2}{2\\tau_1}\\,\\mathrm{e}^{-t/\\tau_1},\n",
    "\\end{align}\n",
    "\n",
    "in this case, as gamma distribution.  Not to worry; we will not include this limit in our analysis here.\n",
    "\n",
    "In fact, you should specify $\\tau_1 < \\tau_2 < \\cdots < \\tau_n$.  Why is this ok to do, and why should you do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** For the trials where the tubulin concentration is 12 µM (from the file `gardner_mt_catastrophe_only_tubulin.csv`), use PTMCMC to perform parameter estimation for the $\\{\\tau_j\\}$ and to perform model selection for various values of $m$.  Report the results with clear graphics and discussion.  \n",
    "\n",
    "*Hint*: Computing the log of the sum of exponentials while dealing with machine precision is a tricky business, and something that comes up often in probability.  Here is my advice.  Say you are computing $\\ln(\\mathrm{e}^a - \\mathrm{e}^b + \\mathrm{e}^c)$ with $a>b>c$.  We have\n",
    "\n",
    "\\begin{align}\n",
    "\\ln(\\mathrm{e}^a - \\mathrm{e}^b + \\mathrm{e}^c) = \\ln\\left(\\mathrm{e}^a(1 - \\mathrm{e}^{b-a} + \\mathrm{e}^{c-a})\\right)\n",
    "= a + \\ln(1 - \\mathrm{e}^{b-a} + \\mathrm{e}^{c-a}).\n",
    "\\end{align}\n",
    "\n",
    "This latter expression is much easier to compute numerically because all entries in the sum inside the logarithm at less than or equal to one, given that $a$ is the largest argument to the exponentials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Using whichever model you found more probable when you computed the odds ratio for the 12 µM tubulin measurements, the values of the $\\tau_j$'s for the other concentrations of tubulin.  Given that microtubules polymerize faster with higher tubulin concentrations, is there anything you can say about the occurrence of catastrophe by looking at the values of the $\\tau_j$'s versus tubulin concentration?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e) (15 points extra credit)** In the files `gardner_mt_catastrophe_kip3.csv` and `gardner_mt_catastrophe_mcak.csv`, there are measurements of catastrophe times in the presence of the kinesins Kip3 and MCAK with 12 µM tubulin.  Analyze these data and discuss conclusions about their respective roles in microtubule catastrophe.  *Note*: This part of the problem is intentionally open-ended.  You should think carefully, and perform a complete analysis to draw your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.1: solution\n",
    "\n",
    "**a)** To be added.\n",
    "\n",
    "**b)** If we order the $\\tau_j$'s, we can write\n",
    "\n",
    "\\begin{align}\n",
    "P(t\\mid \\boldsymbol{\\tau}, m, I) = \\sum_{j=1}^m (-1)^{m-j}\\,\\frac{\\tau_j^{m-2}\\,\\mathrm{e}^{-t/\\tau_j}}{\\prod_{k=1,k\\ne j}^m \\left|\\tau_j - \\tau_k\\right|}.\n",
    "\\end{align}\n",
    "\n",
    "This enables us to write the sum as\n",
    "\n",
    "\\begin{align}\n",
    "P(t\\mid \\boldsymbol{\\tau}, m, I)  = \\sum_{j=1}^m (-1)^{m-j}\\, \\exp\\left\\{-\\frac{t}{\\tau_j} + (m-2) \\ln \\tau_j - \\sum_{k=1,k\\ne j}^m \\ln\\left|\\tau_j-\\tau_k\\right|\\right\\}.\n",
    "\\end{align}\n",
    "\n",
    "The likelihood is then\n",
    "\n",
    "\\begin{align}\n",
    "P(D\\mid \\boldsymbol{\\tau}, m, I) = \\prod_i\\left(\n",
    "\\sum_{j=1}^m (-1)^{m-j}\\, \\exp\\left\\{-\\frac{t_i}{\\tau_j} + (m-2) \\ln \\tau_j - \\sum_{k=1,k\\ne j}^m \\ln\\left|\\tau_j-\\tau_k\\right|\\right\\}\n",
    "\\right),\n",
    "\\end{align}\n",
    "\n",
    "giving a log likelihood of\n",
    "\n",
    "\\begin{align}\n",
    "\\ln P(D\\mid \\boldsymbol{\\tau}, m, I) = \\sum_i \\ln\\left(\\sum_{j=1}^m (-1)^{m-j}\\, \\exp\\left\\{-\\frac{t_i}{\\tau_j} + (m-2) \\ln \\tau_j - \\sum_{k=1,k\\ne j}^m \\ln\\left|\\tau_j-\\tau_k\\right|\\right\\}\\right).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** We need to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def log_likelihood(tau, t, m):\n",
    "    \"\"\"\n",
    "    Log likelihood for waiting time for sequential Poisson processes.\n",
    "    \"\"\"\n",
    "    # Number of data points\n",
    "    n = len(t)\n",
    "    \n",
    "    # Compute special cases first\n",
    "    if m == 1:\n",
    "        return -n * np.log(tau[0]) - np.sum(t / tau[0])\n",
    "    else:\n",
    "        for t_i in t:\n",
    "            exp_args = np.empty(m)\n",
    "            for j, tau_j in enumerate(tau):\n",
    "                exp_args[j] = -t_i / tau_j + (m - 2) * np.log(tau_j)\n",
    "                tau_diff = np.abs(tau[j] - tau)\n",
    "                exp_args[j] -= np.log(tau_diff[tau_diff > 0]).sum()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if model == 'A':\n",
    "        return st.nbinom._logpmf(n, params[0], params[1]).sum()\n",
    "    elif model == 'B':\n",
    "        r_1, p_1, r_2, p_2, f = params\n",
    "        return np.logaddexp(st.nbinom._logpmf(n, r_1, p_1) + np.log(f),\n",
    "                            st.nbinom._logpmf(n, r_2, p_2) + np.log(1-f)).sum()\n",
    "    else:\n",
    "        raise RuntimeError('Invalid model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.misc.logsumexp??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6.2: Spike sorting, 30 pts\n",
    "\n",
    "Dawna and Kyu kindly provided us with another set of voltage measurements from a mouse retina.  You can download the data [here](../data/H930start2filt.txt.zip).  These data have been pre-filtered, so you do not need to do any filtering, unless you think it will help your analysis.  For this trace:\n",
    "\n",
    "**a)** Locate all spikes.\n",
    "\n",
    "**b)** There are two types of spikes.  Devise a way to automatically tell the difference between each type of spike.  Plot all of the spikes overlayed on top of each other with their minima at the same point.  The plot should be color-coded so that two classes of spikes have different colors.\n",
    "\n",
    "**c)** Plot the probability distributions of inter-spike times for each type of spike and comment on anything you see of note."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
